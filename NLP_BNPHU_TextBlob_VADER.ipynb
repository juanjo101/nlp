{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "nipTosJ9GYIG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nipTosJ9GYIG",
        "outputId": "b9de2ce9-4cd0-4cec-8f19-507e44f6f13e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 1 fields in line 3, saw 4462\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3409570792.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mruta_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://drive.google.com/file/d/1NBioQimhCbPaTaXZSlCoqLu85boNFNai/view\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruta_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8-sig\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Primeras filas del dataset:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 4462\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Análisis de comentarios BNPHU con TextBlob y VADER\n",
        "# Archivo: /content/sample_data/comentarios_bnphu.csv\n",
        "# ============================================\n",
        "\n",
        "# Si estás en Colab y no las tienes instaladas, ejecuta UNA VEZ descomentando:\n",
        "# !pip install textblob nltk\n",
        "\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Descargar el lexicón de VADER (solo la primera vez; luego se salta si ya está)\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Crear el analizador de sentimiento VADER\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# ============================================\n",
        "# 1. Cargar el CSV de comentarios\n",
        "# ============================================\n",
        "\n",
        "ruta_csv = \"https://drive.google.com/file/d/1NBioQimhCbPaTaXZSlCoqLu85boNFNai/view\"\n",
        "df = pd.read_csv(ruta_csv, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Primeras filas del dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# ============================================\n",
        "# 2. Funciones de clasificación de sentimiento\n",
        "# ============================================\n",
        "\n",
        "def clasificar_sentimiento(polarity, tol=0.10):\n",
        "    \"\"\"\n",
        "    Clasificación estándar del sentimiento usando la polaridad de TextBlob.\n",
        "    - Positivo: polaridad > tol\n",
        "    - Negativo: polaridad < -tol\n",
        "    - Neutro: en [-tol, tol]\n",
        "    \"\"\"\n",
        "    if polarity > tol:\n",
        "        return \"Positivo\"\n",
        "    elif polarity < -tol:\n",
        "        return \"Negativo\"\n",
        "    else:\n",
        "        return \"Neutro\"\n",
        "\n",
        "\n",
        "def clasificar_institucional(sentimiento):\n",
        "    \"\"\"\n",
        "    Clasificación adaptada a la gestión institucional:\n",
        "    - Negativo -> Necesita atención\n",
        "    - Positivo -> Positivo\n",
        "    - Neutro   -> Neutro\n",
        "    \"\"\"\n",
        "    if sentimiento == \"Negativo\":\n",
        "        return \"Necesita atención\"\n",
        "    elif sentimiento == \"Positivo\":\n",
        "        return \"Positivo\"\n",
        "    else:\n",
        "        return \"Neutro\"\n",
        "\n",
        "\n",
        "def clasificar_sentimiento_vader(compound, tol=0.05):\n",
        "    \"\"\"\n",
        "    Clasificación estándar de VADER usando el 'compound' (-1 a 1).\n",
        "    Umbrales recomendados:\n",
        "    - Positivo: compound >= 0.05\n",
        "    - Negativo: compound <= -0.05\n",
        "    - Neutro: entre -0.05 y 0.05\n",
        "    \"\"\"\n",
        "    if compound >= tol:\n",
        "        return \"Positivo\"\n",
        "    elif compound <= -tol:\n",
        "        return \"Negativo\"\n",
        "    else:\n",
        "        return \"Neutro\"\n",
        "\n",
        "# ============================================\n",
        "# 3. Análisis con TextBlob\n",
        "# ============================================\n",
        "\n",
        "registros_tb = []\n",
        "\n",
        "for c in df[\"comentario\"]:\n",
        "    blob = TextBlob(c)\n",
        "    pol = blob.sentiment.polarity\n",
        "    subj = blob.sentiment.subjectivity\n",
        "    senti_std = clasificar_sentimiento(pol)\n",
        "    senti_inst = clasificar_institucional(senti_std)\n",
        "\n",
        "    registros_tb.append({\n",
        "        \"comentario\": c,\n",
        "        \"polaridad_tb\": pol,\n",
        "        \"subjetividad_tb\": subj,\n",
        "        \"sentimiento_estandar_tb\": senti_std,\n",
        "        \"clasificacion_institucional_tb\": senti_inst\n",
        "    })\n",
        "\n",
        "df_tb = pd.DataFrame(registros_tb)\n",
        "\n",
        "print(\"\\n=== Resultados con TextBlob ===\")\n",
        "display(df_tb.head())\n",
        "\n",
        "# Resumen TextBlob\n",
        "df_sent_tb = df_tb[\"sentimiento_estandar_tb\"].value_counts()\n",
        "df_inst_tb = df_tb[\"clasificacion_institucional_tb\"].value_counts()\n",
        "\n",
        "print(\"\\nResumen – Sentimiento estándar (TextBlob):\\n\")\n",
        "print(df_sent_tb)\n",
        "\n",
        "print(\"\\nResumen – Clasificación institucional (TextBlob):\\n\")\n",
        "print(df_inst_tb)\n",
        "\n",
        "# Gráficas TextBlob\n",
        "plt.figure(figsize=(6,4))\n",
        "df_sent_tb.plot(kind=\"bar\", title=\"Sentimiento estándar – TextBlob\")\n",
        "plt.xlabel(\"Sentimiento\")\n",
        "plt.ylabel(\"Cantidad de comentarios\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "df_inst_tb.plot(kind=\"bar\", title=\"Clasificación institucional – TextBlob\")\n",
        "plt.xlabel(\"Clasificación\")\n",
        "plt.ylabel(\"Cantidad de comentarios\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "# Comentarios que necesitan atención según TextBlob\n",
        "df_necesita_atencion_tb = df_tb[df_tb[\"clasificacion_institucional_tb\"] == \"Necesita atención\"]\n",
        "print(\"\\nComentarios que 'necesitan atención' según TextBlob:\")\n",
        "display(df_necesita_atencion_tb)\n",
        "\n",
        "# ============================================\n",
        "# 4. Análisis con VADER (NLTK)\n",
        "# ============================================\n",
        "\n",
        "registros_vader = []\n",
        "\n",
        "for c in df[\"comentario\"]:\n",
        "    scores = sia.polarity_scores(c)  # dict: {'neg', 'neu', 'pos', 'compound'}\n",
        "    compound = scores[\"compound\"]\n",
        "    senti_std_v = clasificar_sentimiento_vader(compound)\n",
        "    senti_inst_v = clasificar_institucional(senti_std_v)\n",
        "\n",
        "    registros_vader.append({\n",
        "        \"comentario\": c,\n",
        "        \"compound_vader\": compound,\n",
        "        \"neg_vader\": scores[\"neg\"],\n",
        "        \"neu_vader\": scores[\"neu\"],\n",
        "        \"pos_vader\": scores[\"pos\"],\n",
        "        \"sentimiento_estandar_vader\": senti_std_v,\n",
        "        \"clasificacion_institucional_vader\": senti_inst_v\n",
        "    })\n",
        "\n",
        "df_vader = pd.DataFrame(registros_vader)\n",
        "\n",
        "print(\"\\n=== Resultados con VADER (NLTK) ===\")\n",
        "display(df_vader.head())\n",
        "\n",
        "# Resumen VADER\n",
        "df_sent_vader = df_vader[\"sentimiento_estandar_vader\"].value_counts()\n",
        "df_inst_vader = df_vader[\"clasificacion_institucional_vader\"].value_counts()\n",
        "\n",
        "print(\"\\nResumen – Sentimiento estándar (VADER):\\n\")\n",
        "print(df_sent_vader)\n",
        "\n",
        "print(\"\\nResumen – Clasificación institucional (VADER):\\n\")\n",
        "print(df_inst_vader)\n",
        "\n",
        "# Gráficas VADER\n",
        "plt.figure(figsize=(6,4))\n",
        "df_sent_vader.plot(kind=\"bar\", title=\"Sentimiento estándar – VADER\")\n",
        "plt.xlabel(\"Sentimiento\")\n",
        "plt.ylabel(\"Cantidad de comentarios\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "df_inst_vader.plot(kind=\"bar\", title=\"Clasificación institucional – VADER\")\n",
        "plt.xlabel(\"Clasificación\")\n",
        "plt.ylabel(\"Cantidad de comentarios\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "# Comentarios que necesitan atención según VADER\n",
        "df_necesita_atencion_vader = df_vader[df_vader[\"clasificacion_institucional_vader\"] == \"Necesita atención\"]\n",
        "print(\"\\nComentarios que 'necesitan atención' según VADER:\")\n",
        "display(df_necesita_atencion_vader)\n",
        "\n",
        "# ============================================\n",
        "# 5. Comparación TextBlob vs VADER\n",
        "# ============================================\n",
        "\n",
        "df_comparacion = pd.merge(\n",
        "    df_tb[[\"comentario\", \"sentimiento_estandar_tb\", \"clasificacion_institucional_tb\"]],\n",
        "    df_vader[[\"comentario\", \"sentimiento_estandar_vader\", \"clasificacion_institucional_vader\"]],\n",
        "    on=\"comentario\",\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== Comparación TextBlob vs VADER ===\")\n",
        "display(df_comparacion)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
